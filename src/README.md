# üöÄ Databricks RAG Chatbot: Guia de Implementa√ß√£o com Vector Search e LangChain

Este guia passo a passo detalha o processo de constru√ß√£o e deployment de um aplicativo **RAG (Retrieval-Augmented Generation)** usando **LangChain**, **Databricks Vector Search** e **Streamlit**, com deployment final na plataforma Databricks.

O projeto utiliza o cat√°logo Unity do Databricks para armazenar dados de produtos e o Vector Search para criar uma base de conhecimento sem√¢ntica, permitindo que o LLM responda a perguntas complexas sobre o cat√°logo.

---

## üó∫Ô∏è Fluxo do Workshop

O projeto segue o seguinte fluxo de trabalho:

1.  **Cria√ß√£o do Vector Search Index** na tabela `produtos`.
2.  **Configura√ß√£o das Vari√°veis de Ambiente** necess√°rias para a conex√£o.
3.  **Constru√ß√£o da Chain RAG** com LangChain (`main.py`).
4.  **Cria√ß√£o do Frontend** com Streamlit (`app.py`).
5.  **Deployment** do aplicativo no Databricks Compute > Apps.

---

## 1. Cria√ß√£o do Vector Search Index

Para habilitar a busca sem√¢ntica em nosso cat√°logo de produtos, criaremos um Vector Search Index a partir da tabela `ai-agent-workshop.data.produtos`.

**Pr√©-condi√ß√£o:** As tabelas `clientes`, `produtos` e `vendas` j√° devem estar criadas no Unity Catalog.

### üìù Passos no Databricks Workspace

1.  No seu Databricks Workspace, navegue at√© **Catalog**.
2.  Localize a tabela de produtos: `ai-agent-workshop.data.produtos`.
3.  Clique no bot√£o **Create** no canto superior direito e selecione **Vector Search Index**.
4.  Configure o Index com os seguintes par√¢metros:
    * **Source Table:** `ai-agent-workshop.data.produtos`
    * **Primary Key:** `id_produto`
    * **Columns to Sync (Sincronizar):** Marque as colunas que ser√£o retornadas junto com a busca vetorial:
        * `nome_produto`
        * `categoria`
        * `preco`
        * `ativo`
    * **Column to be used for Embedding:** `descricao` (Esta coluna ser√° usada para gerar os vetores).
    * **Embedding Model:** `databricks-gte-large-en`
    * **Vector Search Endpoint:** `my-vector-search` (Certifique-se de que este endpoint esteja ativo. Ele ser√° referenciado no seu c√≥digo como `VS_ENDPOINT`).
5.  Clique em **Create**.

Aguarde o status do Index mudar para `READY`. Este ser√° o seu `INDEX_NAME`.

---

## 2. Configura√ß√£o das Vari√°veis de Ambiente

O aplicativo requer diversas vari√°veis de ambiente para conectar-se aos servi√ßos do Databricks (Vector Search, LLM Endpoint, MLflow) e, opcionalmente, a servi√ßos externos (OpenAI).

Crie um arquivo `.env` ou configure estas vari√°veis diretamente no ambiente de deployment com os seus respectivos valores.

| Vari√°vel | Descri√ß√£o | Exemplo de Valor |
| :--- | :--- | :--- |
| `VS_ENDPOINT` | Nome do seu Endpoint de Vector Search (Criado no Passo 1). | `"my-vector-search"` |
| `INDEX_NAME` | Path completo do Vector Search Index (Cat√°logo.Schema.Index). | `"ai-agent-workshop.data.produtos_index"` |
| `LLM_ENDPOINT` | Endpoint de Serving do LLM a ser usado. | `"databricks-meta-llama-3-3-70b-instruct"` |
| `MODEL_NAME` | Nome para o trace do MLflow. | `"nome-do-trace"` |
| `EXPERIMENT_ID` | ID do Experimento MLflow para rastrear as corridas. | `"seu-id-experimento"` |
| `MLFLOW_TRACKING_URI` | URI para rastreamento do MLflow (geralmente `"databricks"`). | `"databricks"` |
| `DATABRICKS_HOST` | URL do seu Workspace Databricks. | `"https://seu-id.cloud.databricks.com"` |
| `DATABRICKS_TOKEN` | Token de Acesso Pessoal para autentica√ß√£o. | `"seu-token"` |
| `DATABRICKS_ACCOUNT_ID` | ID da sua conta Databricks (opcional, dependendo do uso). | `"seu-id-conta"` |
| `OPENAI_API_KEY` | Chave API da OpenAI (necess√°ria se usar modelos da OpenAI). | `'sua-chave-api-openai'` |

> **Nota:** As vari√°veis `DATABRICKS_HOST` e `DATABRICKS_TOKEN` s√£o essenciais para a autentica√ß√£o no ambiente de deployment, especialmente via Compute Apps.

---

## 3. Constru√ß√£o do C√≥digo (LangChain e Streamlit)

### 3.1. **Cadeia RAG Principal (`main.py`)**

O arquivo `main.py` cont√©m a l√≥gica central do RAG, orquestrada com LangChain.

* **Fun√ß√£o:** `get_rag_chain()`
* **O que faz:**
    1.  **Retriever:** Inicializa o `DatabricksVectorSearch` usando `VS_ENDPOINT` e `INDEX_NAME` para buscar os documentos de produtos mais relevantes com base na consulta do usu√°rio.
    2.  **Prompt Template:** Define a instru√ß√£o (System Prompt) para o LLM, orientando-o a atuar como um **"assistente de recomenda√ß√£o de produtos"** e a usar o contexto recuperado para formatar a resposta.
    3.  **LLM:** Inicializa o `ChatDatabricks` utilizando o `LLM_ENDPOINT` configurado.
    4.  **Chain (LCEL):** Conecta o Retriever, o Prompt e o LLM usando a LangChain Expression Language (`RunnableMap | prompt | llm | StrOutputParser()`), garantindo um fluxo de dados eficiente.

### 3.2. **Interface do Usu√°rio (`app.py`)**

O arquivo `app.py` constr√≥i a interface gr√°fica usando o Streamlit.

* **Fun√ß√£o:** Criar o frontend para intera√ß√£o do usu√°rio com o Chatbot RAG.
* **O que faz:**
    1.  **Inicializa√ß√£o:** Usa `@st.cache_resource` para inicializar a chain LangChain **apenas uma vez** (via `get_rag_chain()`).
    2.  **Hist√≥rico de Chat:** Gerencia as mensagens anteriores usando `st.session_state`.
    3.  **Processamento da Entrada:** Captura a pergunta do usu√°rio (`st.chat_input`).
    4.  **Invoca√ß√£o e MLflow:** Inicia um novo **MLflow Run** (`mlflow.start_run`) para cada consulta, invoca a `chain.invoke()` com a pergunta e registra os par√¢metros de entrada e a resposta, facilitando o rastreamento e a depura√ß√£o.
    5.  **Exibi√ß√£o:** Exibe o hist√≥rico de mensagens e a resposta do assistente no formato de chat.

---

## 4. Deployment no Databricks

Ap√≥s configurar os arquivos e vari√°veis, o aplicativo Streamlit pode ser implantado como um **Databricks App**.

**Pr√©-requisito:** Certifique-se de que voc√™ tem um arquivo de configura√ß√£o como o `app.yaml` que define o comando de execu√ß√£o e as vari√°veis de ambiente a serem passadas.

### üìù Passos para o Deploy

1.  **Pacote de Deployment:** Certifique-se de que todos os arquivos necess√°rios (`main.py`, `app.py`, `settings.py`, `requirements.txt`, `app.yaml`) est√£o prontos para serem empacotados e acessados (ex: em um reposit√≥rio Git ou DBFS).
2.  **Navegue para Apps:** No seu Databricks Workspace, navegue at√© a se√ß√£o **Compute** (Computa√ß√£o).
3.  Selecione a aba **Apps**.
4.  Clique em **Create App**.
5.  Configure os detalhes do App:
    * **Source:** Selecione a fonte do seu c√≥digo (ex: Databricks Repos, que √© altamente recomendado).
    * **App Name:** D√™ um nome ao seu aplicativo (ex: `rag-produtos-streamlit`).
    * **YAML File Path:** Indique o caminho para o seu arquivo de configura√ß√£o de deployment (ex: `app.yaml`).
    * **Cluster/Compute Config:** Selecione ou configure o tipo de recurso de computa√ß√£o onde o app ser√° executado.
    * **Environment Variables:** Adicione as vari√°veis de ambiente listadas no **Passo 2** na se√ß√£o de configura√ß√µes.
6.  Clique em **Create** e monitore o status do seu aplicativo.

Uma vez que o App estiver em status `READY` (Pronto), voc√™ poder√° acessar o link para interagir com o seu Chatbot RAG de Produtos.